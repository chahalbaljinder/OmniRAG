# ğŸ” RAG App â€“ LLM Specialist Assignment

A Retrieval-Augmented Generation (RAG) pipeline that allows users to upload documents and ask contextual questions using FAISS vector search and a powerful LLM (LLaMA-3 via Groq API).

---

## ğŸš€ Features

- Upload **up to 20 PDFs**, max 1000 pages each
- Chunk documents & store embeddings in **FAISS**
- Query documents using **Groq's LLaMA 3 (70B)** LLM
- REST API built with **FastAPI**
- Dockerized for seamless local/cloud deployment
- Environment-configurable for multiple LLM providers

---

## ğŸ§± Tech Stack

- **FastAPI** â€“ API framework  
- **FAISS** â€“ Vector database  
- **SentenceTransformers** â€“ Embedding generation  
- **Groq API** â€“ High-performance LLMs  
- **Docker** â€“ Deployment containerization

---

## âš™ï¸ Setup

### 1. Clone the repo & install dependencies

```bash
git clone <your-repo-url>
cd rag_app
```

### 2. Add `.env` file

Create a `.env` file:

```env
GROQ_API_KEY=gsk_live_your_api_key_here
```

### 3. Build and run via Docker

```bash
docker-compose up --build
```

> App will be available at `http://localhost:8000/docs`

---

## ğŸ§ª API Usage

### `POST /upload`
Upload up to 20 PDF files

- `files`: `multipart/form-data`

### `POST /query`
Ask a question based on all uploaded PDFs

- `query`: form field

### `GET /documents`
View metadata of all uploaded documents

---

## ğŸ§ª Example CURL

```bash
curl -X POST http://localhost:8000/upload \
  -F "files=@unit1.pdf" \
  -F "files=@unit2.pdf"

curl -X POST http://localhost:8000/query \
  -d "query=What is unit 1 about?" \
  -H "Content-Type: application/x-www-form-urlencoded"
```

---

## ğŸ”„ Switching to OpenAI/Gemini

You can swap `rag.py` logic to use `openai.ChatCompletion.create()` or Google Gemini easily. Refer to respective SDKs and update the `.env`.

---

## ğŸ“‚ Folder Structure

```
rag_app/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api.py
â”‚   â”œâ”€â”€ rag.py
â”‚   â”œâ”€â”€ embedding.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ main.py
â”œâ”€â”€ uploads/               â† stores uploaded PDFs
â”œâ”€â”€ indexes/               â† stores FAISS indexes
â”œâ”€â”€ .env                   â† your API key config
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## âœ… Status

âœ… Fully working  
ğŸ§ª Test-ready via Swagger & Postman  
ğŸš¢ Deployable on cloud or local  

---

## ğŸ‘¤ Author

Anmol Airi â€“ https://github.com/anmolairi03/pan-science-rag-pipeline/
